# âœ… STEP 1: Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

from sklearn.preprocessing import StandardScaler, MinMaxScaler

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# âœ… STEP 2: Load Dataset
df = pd.read_csv("/content/ai_stock_data.csv")  # Updated path
print("Initial DataFrame shape:", df.shape)
print(df.head())

# âœ… STEP 3: Data Preprocessing
# Convert 'Date' column if exists
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')

# Drop rows with missing values and duplicates
df = df.dropna()
df = df.drop_duplicates()
print("Cleaned DataFrame shape:", df.shape)

# âœ… STEP 4: Feature Normalization (Standard Scaler)
features = ['Open', 'High', 'Low', 'Cls', 'Volume']  # Use 'Cls' for Close price
scaler = StandardScaler()
df[features] = scaler.fit_transform(df[features])

# âœ… STEP 5: Feature Engineering
df['MA_5'] = df['Cls'].rolling(window=5).mean()
df['MA_10'] = df['Cls'].rolling(window=10).mean()
df['RSI'] = df['Cls'].diff().apply(lambda x: max(x, 0)).rolling(window=14).mean()

df = df.dropna()

# âœ… STEP 6: Train-Test Split
X = df[['Open', 'High', 'Low', 'Volume', 'MA_5', 'MA_10', 'RSI']]
y = df['Cls']  # Use 'Cls' for Close price

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# âœ… STEP 7: Linear Regression
lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

# âœ… STEP 8: Random Forest
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

# âœ… STEP 9: Model Evaluation
def evaluate(y_true, y_pred, model_name):
    print(f"\nðŸ“Š {model_name} Evaluation:")
    print("MAE:", mean_absolute_error(y_true, y_pred))
    print("RMSE:", np.sqrt(mean_squared_error(y_true, y_pred)))
    print("R2 Score:", r2_score(y_true, y_pred))

evaluate(y_test, y_pred_lr, "Linear Regression")
evaluate(y_test, y_pred_rf, "Random Forest")

# âœ… STEP 10: Visualization
plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label='Actual')
plt.plot(y_pred_rf, label='Predicted - Random Forest')
plt.legend()
plt.title("Actual vs Predicted Stock Prices")
plt.xlabel("Samples")
plt.ylabel("Normalized Close Price")
plt.grid(True)
plt.show()

# âœ… OPTIONAL STEP 11: LSTM Model (Univariate for 'Close' Price)

# âž¤ Prepare data for LSTM
df_lstm = df[['Cls']]  # Use 'Cls' for Close price
scaler_lstm = MinMaxScaler()
df_lstm_scaled = scaler_lstm.fit_transform(df_lstm)

X_seq, y_seq = [], []
window = 60

for i in range(window, len(df_lstm_scaled)):
    X_seq.append(df_lstm_scaled[i-window:i, 0])
    y_seq.append(df_lstm_scaled[i, 0])

X_seq, y_seq = np.array(X_seq), np.array(y_seq)
X_seq = X_seq.reshape((X_seq.shape[0], X_seq.shape[1], 1))

# âž¤ Split into train/test
split_index = int(len(X_seq) * 0.8)
X_train_lstm, X_test_lstm = X_seq[:split_index], X_seq[split_index:]
y_train_lstm, y_test_lstm = y_seq[:split_index], y_seq[split_index:]

# âž¤ Build LSTM Model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_seq.shape[1], 1)))
model.add(LSTM(50))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mean_squared_error')

# âž¤ Train Model
model.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=32, verbose=1)

# âž¤ Predict and Evaluate
y_pred_lstm = model.predict(X_test_lstm)
y_pred_lstm = scaler_lstm.inverse_transform(y_pred_lstm.reshape(-1, 1))
y_test_lstm_orig = scaler_lstm.inverse_transform(y_test_lstm.reshape(-1, 1))

# âž¤ Plot LSTM Results
plt.figure(figsize=(12, 6))
plt.plot(y_test_lstm_orig, label='Actual')
plt.plot(y_pred_lstm, label='Predicted - LSTM')
plt.title("LSTM Model - Actual vs Predicted Stock Prices")
plt.xlabel("Samples")
plt.ylabel("Original Close Price")
plt.legend()
plt.grid(True)
plt.show()
